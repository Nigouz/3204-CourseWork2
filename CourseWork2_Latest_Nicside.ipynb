{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nigouz/3204-CourseWork2/blob/KNN/CourseWork2_Latest_Nicside.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZhD1QKdgcK9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import os\n",
        "import re\n",
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VY4YBaFhgmtT"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cu1B4nd9gmq8"
      },
      "outputs": [],
      "source": [
        "#FOR COURSEWORK\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "full_df = pd.read_csv(r\"shuffled-noIPV6.csv\")\n",
        "# df = pd.read_csv(\"truncated_training.csv\")\n",
        "\n",
        "print(f\"[*] Shape of dataset: {full_df.shape}\")\n",
        "from sklearn.utils import shuffle\n",
        "full_df.drop(full_df.columns[0], axis=1, inplace=True)\n",
        "full_df = shuffle(full_df)\n",
        "\n",
        "print(full_df.tail())\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOgcXWdIzNSq"
      },
      "outputs": [],
      "source": [
        "#COURSEWORK\n",
        "full_df[\"src_port\"]=  full_df[\"src_port\"].replace(regex=\",\", value= \"\")\n",
        "full_df[\"src_port\"]=  full_df[\"src_port\"].replace(regex=\",\", value= \"\")\n",
        "full_df[\"dst_port\"]=  full_df[\"dst_port\"].replace(regex=\",\", value= \"\")\n",
        "full_df[\"dst_port\"]=  full_df[\"dst_port\"].replace(regex=\" \", value= \"\")\n",
        "full_df[\"src_port\"] = full_df[\"src_port\"].replace(regex=\" \", value=\"\")\n",
        "full_df[\"src_port\"] = full_df[\"src_port\"].replace(regex=\"dns\", value=\"53\")\n",
        "full_df[\"src_port\"] = full_df[\"src_port\"].replace(regex=\"tls\", value=\"0\")\n",
        "full_df[\"dst_port\"] = full_df[\"dst_port\"].replace(regex=\"dns\", value=\"53\")\n",
        "full_df[\"dst_ip\"] = full_df[\"dst_ip\"].replace(regex=\"\\S*:+\\S+\", value=\"0\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Lab Files\"\"\" \n",
        "data4 = pd.read_csv(\"IanArffDataset.csv\", delimiter=\",\")\n",
        "#print(\"test1\", data4)\n",
        "d4 = data4.replace('?', 0)\n",
        "d4.head()\n",
        "print(f\"[*] Shape of dataset: {d4.shape}\")\n",
        "d4.tail()\n",
        "d4 = d4.dropna()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bsflZRv-6u_",
        "outputId": "3aaf782b-8539-4e2d-a479-a4a61814d7fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*] Shape of dataset: (188508, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"For LAB 8 \"\"\"\n",
        "#Data pre-processing\n",
        "d4 = d4.rename(columns={\"'address'\": \"address\", \"'function'\": \"function\"})\n",
        "d4 = d4.rename(columns={\"'length'\": \"length\", \"'setpoint'\": \"setpoint\", \"'gain'\": \"gain\", \"'reset\": \"reset\", \"'deadband'\": \"deadband\", \"'cycle\": \"cycle\"})\n",
        "d4 = d4.rename(columns={\"'rate'\": \"rate\", \"'system\": \"system\", \"'control\": \"control\", \"'pump'\": \"pump\", \"'solenoid'\": \"solenoid\", \"'pressure\": \"pressure\"})\n",
        "d4 = d4.rename(columns={\"'crc\": \"crc\", \"'command response'\": \"command response\", \"'time'\": \"time\", \"'binary result'\": \"binary result\", \"'categorized\": \"categorized\", \"'specific\": \"specific\"})\n",
        "\n",
        "#print (\"test3\", d4)\n",
        "#convert columns with object type to float64\n",
        "d4 = d4.astype({'setpoint':'float64', 'gain':'float64', 'reset':'float64', 'deadband':'float64', 'cycle':'float64', 'rate':'float64', 'system':'float64', 'control':'float64', 'pump':'float64', 'solenoid':'float64', 'pressure':'float64'})\n",
        "\n",
        "feature_d4 = d4[['address', 'function', 'length', 'setpoint', 'gain', 'reset', 'deadband', 'cycle', 'rate', 'system', 'control', 'pump', 'solenoid', 'pressure', 'crc', 'command response']]\n",
        "X = np.asarray(feature_d4)\n",
        "#print (\"test5\", X)\n",
        "\n",
        "Y = d4['binary result']\n",
        "print('x shape=', X.shape)\n",
        "print('y shape=', Y.shape)\n",
        "\n",
        "X = preprocessing.StandardScaler().fit(X).transform(X.astype(float)) #specifically for knn\n",
        "#print (X)"
      ],
      "metadata": {
        "id": "4ry9gXx--_U2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"Lab 8 training\"\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)"
      ],
      "metadata": {
        "id": "83ukrMoE_EEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrekodUTmBym"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "scores = {}\n",
        "scores_list= []\n",
        "\n",
        "def scoring_metrics(y_test, y_pred, model):\n",
        "    print(f\"y_test size:{y_test.size} y_pred size:{y_pred.size}\")\n",
        "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "    scores[model] = accuracy\n",
        "    scores_list.append(accuracy)\n",
        "#     confusion_matrix = metrics.confusion_matrix(y_true=[True, True], y_pred=[True, True], labels=[True, False])\n",
        "    #For the Coursework its the following line\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=['nmap_scan', 'port_scan', 'smtp_enumeration', 'sql_enumeration', 'web_enumeration'])\n",
        "    \"\"\"For LAB 8\"\"\"\n",
        "    #cm = confusion_matrix(y_test, y_pred)\n",
        "    print(f\"Confusion Matrix: {cm}\")\n",
        "\n",
        "    print(f\"\\n[*] Model: {model}\")\n",
        "    print(\"[*] Precision: {:.3f}%\".format(metrics.precision_score(y_test, y_pred, average=\"weighted\")))\n",
        "    print(\"[*] Recall: {:.3f}%\".format(metrics.recall_score(y_test, y_pred, average=\"weighted\")))\n",
        "\n",
        "    print(\"[*] Accuracy: {:.3f}%\".format(accuracy))\n",
        "    print(\"[*] F1_score: {:.3f}%\".format(metrics.f1_score(y_test, y_pred, average=\"weighted\")))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiRQu2ekMSlv"
      },
      "source": [
        "# KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YwJ0elW05h0"
      },
      "outputs": [],
      "source": [
        "df = full_df.head(20000)\n",
        "# df = full_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qd8IISrRwcsl",
        "outputId": "e6d2f17c-10fe-40f2-88cb-55da60b702ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Doing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:5244: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  method=method,\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ],
      "source": [
        "print(\"Doing\")\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "df.replace(to_replace=[\"None\"], value=np.nan, inplace=True)\n",
        "clean_df = df.fillna(str(0)) #uhm i dont knowhow to explain this, but please lmk another alternative to fix this cause :\") try to run it without str and you will know what i mean\"\n",
        "clean_x = clean_df.iloc[:, :13].values\n",
        "clean_y = clean_df[\"category\"].values\n",
        "features = df.columns.values[:-1]\n",
        "\n",
        "for label in clean_df.columns:\n",
        "    for index, rows in clean_df.iterrows():\n",
        "        new_ip = \"\"\n",
        "        ip = str(rows[label])\n",
        "        if re.search(\"\\d+\\.\\d+\\.\\d+\\.\\d+\", ip):\n",
        "            octets = ip.split(\".\")\n",
        "            for octet in octets:\n",
        "                octet = octet.rjust(3,\"0\")\n",
        "                new_ip += octet\n",
        "            clean_df[label][index] = new_ip\n",
        "\n",
        "clean_df[\"http_response_code\"] = clean_df[\"http_response_code\"].replace('HTTP/1.1\"', value=\"0\")\n",
        "clean_df[\"src_ip\"] = clean_df[\"src_ip\"].replace('::1', value=\"0\")\n",
        "clean_df[\"dst_ip\"] = clean_df[\"dst_ip\"].replace('::1', value=\"0\")\n",
        "# clean_df[\"http_response_code\"] = clean_df[\"http_response_code\"].replace('HTTP/1.1\"', value=\"0\")\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HO2a6ef4Cxl3"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import make_column_transformer\n",
        "clean_x = clean_df.iloc[:, :13] #honestly don't know if this is correct lmaoooo\n",
        "#this is to iterate through the columns and convert the strings to float (passthrough means for those columns we didnt specify, leave it as it is)\n",
        "column_trans = make_column_transformer((OneHotEncoder(sparse=False), ['Protocol', 'http_request_method', 'http_request_referrer', 'url_path', 'user_agent_original', 'sql_method', 'sql_query']),remainder='passthrough')\n",
        "test = column_trans.fit_transform(clean_x) #this is technically our cl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZM3UFeBwmLhY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "2430f226-0273-4592-9793-8c60f64add47"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-edabfefd19e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2415\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2417\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \"\"\"\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \"\"\"\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             raise TypeError(\n\u001b[0;32m--> 270\u001b[0;31m                 \u001b[0;34m\"Singleton array %r cannot be considered a valid collection.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             )\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m# Check that shape is returning an integer or default to len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Singleton array array(StandardScaler(), dtype=object) cannot be considered a valid collection."
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
        "x_train, x_test, y_train, y_test = train_test_split(test, clean_y, test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2zTbwdWmpJ6"
      },
      "outputs": [],
      "source": [
        "# k = 5\n",
        "# knn = KNeighborsClassifier(n_neighbors=k)\n",
        "# knn.fit(x_train, y_train)\n",
        "# print(f\"Saving trained model to test-knn{k}.sav\")\n",
        "# pickle.dump(knn, open(f\"test-knn{k}.sav\", \"wb\"))\n",
        "# print(\"Model Saved\")\n",
        "\n",
        "# print(\"Loading knn from pickle\")\n",
        "# knn = pickle.load(open(\"knn5.sav\", \"rb\"))\n",
        "# print(\"KNN Successfully loaded\")\n",
        "\n",
        "# y_pred = knn.predict(x_test)\n",
        "# scoring_metrics(y_test, y_pred, f\"knn {k}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUxr9QPE05h2",
        "outputId": "fd8df6df-31fe-46da-97c1-42ddd69badd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_test size:56553 y_pred size:56553\n",
            "Confusion Matrix: [[41802  2312]\n",
            " [ 6712  5727]]\n",
            "\n",
            "[*] Model: knn 3\n",
            "[*] Precision: 0.829%\n",
            "[*] Recall: 0.840%\n",
            "[*] Accuracy: 0.840%\n",
            "[*] F1_score: 0.827%\n",
            "y_test size:56553 y_pred size:56553\n",
            "Confusion Matrix: [[43042  1072]\n",
            " [ 7411  5028]]\n",
            "\n",
            "[*] Model: knn 4\n",
            "[*] Precision: 0.847%\n",
            "[*] Recall: 0.850%\n",
            "[*] Accuracy: 0.850%\n",
            "[*] F1_score: 0.829%\n"
          ]
        }
      ],
      "source": [
        "scores = {}\n",
        "scores_list= []\n",
        "\n",
        "range_k = range(3, 5)\n",
        "knn = \"\"\n",
        "skip = False\n",
        "\n",
        "\n",
        "for k in range_k:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(x_train, y_train)\n",
        "\n",
        "    y_pred = knn.predict(x_test)\n",
        "    scoring_metrics(y_test, y_pred, f\"knn {k}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uF6l7KtgzNSu"
      },
      "outputs": [],
      "source": [
        "# y_pred.tofile(\"y_pred\", sep=\",\")\n",
        "# y_test.tofile(\"y_test\", sep=\",\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIDN-3D905h3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cf_test = confusion_matrix(y_test, y_pred, labels=['nmap_scan', 'port_scan', 'smtp_enumeration', 'sql_enumeration', 'web_enumeration'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIvBIZD405h3",
        "outputId": "1c65201b-905e-4fe2-aa67-133c12e0f8f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['nmap_scan', 'port_scan', 'port_scan', ..., 'port_scan',\n",
              "       'port_scan', 'web_enumeration'], dtype=object)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgZMq4iG05h3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}