{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nigouz/3204-CourseWork2/blob/main/onehotencoding_3204_Coursework2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZhD1QKdgcK9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import os\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VY4YBaFhgmtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  %matplotlib inline\n",
        "  plt.style.use('ggplot')\n",
        "  # df = pd.read_json('/content/drive/MyDrive/3204 CourseWork 2/Gp15_dataset/raw_logs/filebeat_raw_Gp15_all.json', lines=True)\n",
        "  df = pd.read_csv(\"combinedtraining_dataset.csv\")\n",
        "  #df = pd.read_csv(\"smalldata.csv\")\n",
        "\n",
        "  print(f\"[*] Shape of dataset: {df.shape}\")\n",
        "  print(df.head())\n",
        "  #print(df.tail())\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu1B4nd9gmq8",
        "outputId": "b252c31e-00a8-4fcf-a281-a2cf1f360e60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*] Shape of dataset: (98411, 14)\n",
            "     @timestamp         src_ip src_port      dst_ip dst_port Protocol  \\\n",
            "0  1.666574e+09  192.168.0.102     None   10.0.2.15     None    HTTPS   \n",
            "1  1.666574e+09  192.168.0.102     None  172.17.0.1     None    HTTPS   \n",
            "2  1.666574e+09  192.168.0.102     None  172.18.0.1     None    HTTPS   \n",
            "3  1.666574e+09  192.168.0.102     None   10.0.2.15     None    HTTPS   \n",
            "4  1.666574e+09  192.168.0.102     None  172.17.0.1     None    HTTPS   \n",
            "\n",
            "  http_request_method http_request_referrer http_response_code url_path  \\\n",
            "0                 GET                  None                200        /   \n",
            "1                 GET                  None                200        /   \n",
            "2                 GET                  None                200        /   \n",
            "3                 GET                  None                200        /   \n",
            "4                 GET                  None                200        /   \n",
            "\n",
            "  user_agent_original sql_method sql_query         category  \n",
            "0                None       None      None  web_enumeration  \n",
            "1                None       None      None  web_enumeration  \n",
            "2                None       None      None  web_enumeration  \n",
            "3                None       None      None  web_enumeration  \n",
            "4                None       None      None  web_enumeration  \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.iloc[:, :13].values\n",
        "y = df[\"category\"].values\n",
        "features = df.columns.values[:-1]"
      ],
      "metadata": {
        "id": "R4dqG_nj2VOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "scores = {}\n",
        "scores_list= []\n",
        "\n",
        "def scoring_metrics(y_test, y_pred, model):\n",
        "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "    scores[model] = accuracy\n",
        "    scores_list.append(accuracy)\n",
        "    confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\n[*] Model: {model}\")\n",
        "    print(\"[*] [green bold]True Positive:[/green bold] {}\".format(confusion_matrix[0][0]))\n",
        "    print(\"[*] [red bold]False Positive:[/red bold] {}\".format(confusion_matrix[1][0]))\n",
        "    print(\"[*] [red bold]False Negative:[/red bold] {}\".format(confusion_matrix[0][1]))\n",
        "    print(\"[*] [green bold]True Negative:[/green bold] {}\".format(confusion_matrix[1][1]))\n",
        "    print(\"[*] Precision: {:.3f}%\".format(metrics.precision_score(y_test, y_pred,pos_label='port_scan')))\n",
        "    print(\"[*] Recall: {:.3f}%\".format(metrics.recall_score(y_test, y_pred,pos_label='port_scan')))\n",
        "\n",
        "    print(\"[*] Accuracy: {:.3f}%\".format(accuracy))\n",
        "    print(\"[*] F1_score: {:.3f}%\".format(metrics.f1_score(y_test, y_pred,pos_label='port_scan')))\n"
      ],
      "metadata": {
        "id": "LrekodUTmBym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN"
      ],
      "metadata": {
        "id": "aiRQu2ekMSlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"from sklearn import preprocessing\n",
        "\n",
        "df.replace(to_replace=[\"None\"], value=np.nan, inplace=True)\n",
        "clean_df = df.fillna(0)\n",
        "clean_x = clean_df.iloc[:, :13].values\n",
        "clean_y = clean_df[\"category\"].values\n",
        "features = df.columns.values[:-1]\n",
        "\n",
        "for label in clean_df.columns:\n",
        "    for index, rows in clean_df.iterrows():\n",
        "        new_ip = \"\"\n",
        "        ip = str(rows[label])\n",
        "        if re.search(\"\\d+\\.\\d+\\.\\d+\\.\\d+\", ip):\n",
        "            octets = ip.split(\".\")\n",
        "            for octet in octets:\n",
        "                octet = octet.rjust(3,\"0\")\n",
        "                new_ip += octet\n",
        "            clean_df[label][index] = new_ip\n",
        "\n",
        "#to label encode our data\n",
        "def labelencode(data):\n",
        "  le = preprocessing.LabelEncoder()\n",
        "  nonull = np.array(data.dropna())\n",
        "  impute_reshape = nonull.reshape(-1,1)\n",
        "  impute_encode = le.fit_transform(impute_reshape)\n",
        "  data.loc [data.notnull()]= np.squeeze(impute_encode)\n",
        "  print(data)\n",
        "\n",
        "\n",
        "labelencode(clean_df[\"Protocol\"])\n",
        "clean_x = clean_df.iloc[:, :13].values\n",
        "clean_y = clean_df[\"category\"].values\n",
        "features = df.columns.values[:-1]\n",
        "\n",
        "(clean_df.iloc[:,:13]).info()\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Qd8IISrRwcsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-qxo7U2r6q71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "df.replace(to_replace=[\"None\"], value=np.nan, inplace=True)\n",
        "clean_df = df.fillna(str(0)) #uhm i dont knowhow to explain this, but please lmk another alternative to fix this cause :\") try to run it without str and you will know what i mean\"\n",
        "clean_x = clean_df.iloc[:, :13].values\n",
        "clean_y = clean_df[\"category\"].values\n",
        "features = df.columns.values[:-1]\n",
        "\n",
        "for label in clean_df.columns:\n",
        "    for index, rows in clean_df.iterrows():\n",
        "        new_ip = \"\"\n",
        "        ip = str(rows[label])\n",
        "        if re.search(\"\\d+\\.\\d+\\.\\d+\\.\\d+\", ip):\n",
        "            octets = ip.split(\".\")\n",
        "            for octet in octets:\n",
        "                octet = octet.rjust(3,\"0\")\n",
        "                new_ip += octet\n",
        "            clean_df[label][index] = new_ip\n",
        "\n",
        "\"\"\"\n",
        "#print(df.dtypes) \n",
        "#print(df[\"Protocol\"].unique())  \n",
        "enc = OneHotEncoder(handle_unknown='ignore') #ignore any unknown categories\n",
        "npdata = np.array(clean_df[[\"Protocol\",\"http_request_method\"]])\n",
        "reshapeddata = npdata.reshape(-1,1)\n",
        "\n",
        "onehotencode(clean_df[\"Protocol\"])\n",
        "clean_x = clean_df.iloc[:, :13].values\n",
        "clean_y = clean_df[\"category\"].values\n",
        "features = df.columns.values[:-1]\n",
        "\n",
        "(clean_df.iloc[:,:13]).info()\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2e853d97-098b-4b51-e079-c843c8bf1fbc",
        "id": "VODlanx96rDS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'onehotencode(clean_df[\"Protocol\"])\\nclean_x = clean_df.iloc[:, :13].values\\nclean_y = clean_df[\"category\"].values\\nfeatures = df.columns.values[:-1]\\n\\n(clean_df.iloc[:,:13]).info()'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import make_column_transformer\n",
        "clean_x = clean_df.iloc[:, :13] #honestly don't know if this is correct lmaoooo\n",
        "#this is to iterate through the columns and convert the strings to float (passthrough means for those columns we didnt specify, leave it as it is)\n",
        "column_trans = make_column_transformer((OneHotEncoder(sparse=False), ['Protocol', 'http_request_method', 'url_path', 'user_agent_original']),remainder='passthrough')\n",
        "test = column_trans.fit_transform(clean_x) #this is technically our clean_x after the column transfer "
      ],
      "metadata": {
        "id": "o8sGmeeMRZpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"feature_array= enc.fit_transform(reshapeddata)\n",
        "print(feature_array)\n",
        "enc.categories_\n",
        "feature_labels = enc.categories_\n",
        "feature_labels =np.array(feature_labels).ravel()\n",
        "print (feature_labels)\"\"\""
      ],
      "metadata": {
        "id": "GhtTFq5-JsV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
        "x_train, x_test, y_train, y_test = train_test_split(test, clean_y, test_size=0.3)"
      ],
      "metadata": {
        "id": "ZM3UFeBwmLhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 5\n",
        "knn = KNeighborsClassifier(n_neighbors=k)\n",
        "knn.fit(x_train, y_train)\n",
        "pickle.dump(knn, open(f\"knn{k}.sav\", \"wb\"))\n",
        "\n",
        "y_pred = knn.predict(x_test)\n",
        "scoring_metrics(y_test, y_pred, f\"knn {k}\")"
      ],
      "metadata": {
        "id": "x2zTbwdWmpJ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6ea9078-c200-4185-d9ae-db95e1cc6883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[*] Model: knn 5\n",
            "[*] [green bold]True Positive:[/green bold] 68\n",
            "[*] [red bold]False Positive:[/red bold] 0\n",
            "[*] [red bold]False Negative:[/red bold] 1\n",
            "[*] [green bold]True Negative:[/green bold] 8\n",
            "[*] Precision: 1.000%\n",
            "[*] Recall: 0.986%\n",
            "[*] Accuracy: 0.987%\n",
            "[*] F1_score: 0.993%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM"
      ],
      "metadata": {
        "id": "CIF6JtlMMYpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# instantiate the model\n",
        "svm = SVC(kernel='linear', C=1.0, random_state=12)\n",
        "#fit the model\n",
        "svm.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "B6K2QSVUgmZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predicting the target value from the model for the samples\n",
        "y_test_svm = svm.predict(X_test)\n",
        "y_train_svm = svm.predict(X_train)"
      ],
      "metadata": {
        "id": "W_bcJ2ZZNe6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#computing the accuracy of the model performance\n",
        "acc_train_svm = accuracy_score(y_train,y_train_svm)\n",
        "acc_test_svm = accuracy_score(y_test,y_test_svm)"
      ],
      "metadata": {
        "id": "fMoySC2XNiya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Isolation Forest"
      ],
      "metadata": {
        "id": "oebMHf6YMc5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json('logs.json', lines=True)\n",
        "df = df[]"
      ],
      "metadata": {
        "id": "wTw7DyUFMgNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t-YYihZw8Fjb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}