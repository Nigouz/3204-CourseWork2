{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KZhD1QKdgcK9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import seaborn as sb\n",
    "import flask\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cu1B4nd9gmq8",
    "outputId": "42ea020f-2338-4d4c-9f1b-6916a434622f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Shape of dataset: (92704, 15)\n",
      "       @timestamp           src_ip src_port         dst_ip dst_port  \\\n",
      "76481  1666692146     100.64.19.22     8443  100.64.19.103    44618   \n",
      "91511  1666591980                0        0      10.0.0.20       80   \n",
      "47782  1666582470  192.168.207.142        0              0        0   \n",
      "20890  1666542593    192.168.1.225    54744   40.90.184.73      443   \n",
      "3241   1666532299      192.168.0.3        0              0        0   \n",
      "\n",
      "                                                Protocol http_request_method  \\\n",
      "76481                                                TCP                   0   \n",
      "91511                                                  0                   0   \n",
      "47782                                              HTTPS                 GET   \n",
      "20890  2022-10-24 00:29:24 ALLOW TCP 192.168.1.225 40...                 TCP   \n",
      "3241                                                   0                   0   \n",
      "\n",
      "      http_request_referrer http_response_code           url_path  \\\n",
      "76481                     0                  0                  0   \n",
      "91511                     0                  0                  0   \n",
      "47782                     0                404  /Program%20Files/   \n",
      "20890                     0                  0                  0   \n",
      "3241                      0                  0                  0   \n",
      "\n",
      "      user_agent_original sql_method sql_query          category  \n",
      "76481                   0          0         0         port_scan  \n",
      "91511                   0          0         0   sql_enumeration  \n",
      "47782        Mozilla/5.00          0         0   web_enumeration  \n",
      "20890                   0          0         0         port_scan  \n",
      "3241                    0          0         0  smtp_enumeration  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "# full_df = pd.read_csv(r\"C:\\Users\\Nicz\\Documents\\GitHub\\3204-CourseWork2\\shuffled-noIPV6.csv\")\n",
    "full_df = pd.read_csv(r\"shuffled-noIPV6.csv\")\n",
    "\n",
    "print(f\"[*] Shape of dataset: {full_df.shape}\")\n",
    "from sklearn.utils import shuffle\n",
    "full_df.drop(full_df.columns[0], axis=1, inplace=True)\n",
    "full_df = shuffle(full_df)\n",
    "\n",
    "print(full_df.tail())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IOgcXWdIzNSq"
   },
   "outputs": [],
   "source": [
    "full_df[\"src_port\"]=  full_df[\"src_port\"].replace(regex=\",\", value= \"\")\n",
    "full_df[\"src_port\"]=  full_df[\"src_port\"].replace(regex=\",\", value= \"\")\n",
    "full_df[\"dst_port\"]=  full_df[\"dst_port\"].replace(regex=\",\", value= \"\")\n",
    "full_df[\"dst_port\"]=  full_df[\"dst_port\"].replace(regex=\" \", value= \"\")\n",
    "full_df[\"src_port\"] = full_df[\"src_port\"].replace(regex=\" \", value=\"\")\n",
    "full_df[\"src_port\"] = full_df[\"src_port\"].replace(regex=\"dns\", value=\"53\")\n",
    "full_df[\"src_port\"] = full_df[\"src_port\"].replace(regex=\"tls\", value=\"0\")\n",
    "full_df[\"dst_port\"] = full_df[\"dst_port\"].replace(regex=\"dns\", value=\"53\")\n",
    "full_df[\"dst_ip\"] = full_df[\"dst_ip\"].replace(regex=\"\\S*:+\\S+\", value=\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LrekodUTmBym"
   },
   "outputs": [],
   "source": [
    "scores = {}\n",
    "scores_list= []\n",
    "\n",
    "k_value=[]\n",
    "model_scores={}\n",
    "accuracy_dict={}\n",
    "precision_dict={}\n",
    "cm_dict={}\n",
    "recall_dict={}\n",
    "f1_dict={}\n",
    "\n",
    "algo_accuracy={}\n",
    "algo_precision={}\n",
    "algo_recall={}\n",
    "algo_f1={}\n",
    "\n",
    "def scoring_metrics(y_test, y_pred, model):\n",
    "    print(f\"y_test size:{y_test.size} y_pred size:{y_pred.size}\")\n",
    "    KNN_accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    KNN_precision = metrics.precision_score(y_test, y_pred, average=\"weighted\")\n",
    "    KNN_recall = metrics.recall_score(y_test, y_pred, average=\"weighted\")\n",
    "    KNN_f1_score = metrics.f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    \n",
    "    scores[model] = KNN_accuracy\n",
    "    scores_list.append(KNN_accuracy)\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred, labels=['-','nmap_scan', 'port_scan', 'smtp_enumeration', 'sql_enumeration', 'web_enumeration'])\n",
    "    \n",
    "    k_value.append(model)\n",
    "    accuracy_dict[model]= KNN_accuracy\n",
    "    precision_dict[model]= KNN_precision\n",
    "    recall_dict[model]= KNN_recall\n",
    "    f1_dict[model]= KNN_f1_score\n",
    "        \n",
    "    print(f\"Confusion Matrix: {cm}\")\n",
    "    \n",
    "    print(f\"\\n[*] Model: {model}\")\n",
    "    print(\"[*]Precision: {:.3f}%\".format(KNN_precision))\n",
    "    print(\"[*] Recall: {:.3f}%\".format(KNN_recall))\n",
    "\n",
    "    print(\"[*] Accuracy: {:.3f}%\".format(KNN_accuracy))\n",
    "    print(\"[*] F1_score: {:.3f}%\".format(KNN_f1_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "s7LbyI4qMQDu"
   },
   "outputs": [],
   "source": [
    "# df = full_df.head(25000)\n",
    "df = full_df.head(1000)\n",
    "data_orig = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qd8IISrRwcsl",
    "outputId": "8006e4d9-070e-4cec-9d2d-65b0caeb6d4f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kahow\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n",
      "<ipython-input-6-be49f98fa88c>:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df[label][index] = new_ip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Doing\")\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "df.replace(to_replace=[\"None\"], value=np.nan, inplace=True)\n",
    "clean_df = df.fillna(str(0))\n",
    "clean_x = clean_df.iloc[:, :13].values\n",
    "clean_y = clean_df[\"category\"].values\n",
    "features = df.columns.values[:-1]\n",
    "\n",
    "for label in clean_df.columns:\n",
    "    for index, rows in clean_df.iterrows():\n",
    "        new_ip = \"\"\n",
    "        ip = str(rows[label])\n",
    "        if re.search(\"\\d+\\.\\d+\\.\\d+\\.\\d+\", ip):\n",
    "            octets = ip.split(\".\")\n",
    "            for octet in octets:\n",
    "                octet = octet.rjust(3,\"0\")\n",
    "                new_ip += octet\n",
    "            clean_df[label][index] = new_ip\n",
    "\n",
    "clean_df[\"http_response_code\"] = clean_df[\"http_response_code\"].replace('HTTP/1.1\"', value=\"0\")\n",
    "clean_df[\"src_ip\"] = clean_df[\"src_ip\"].replace('::1', value=\"0\")\n",
    "clean_df[\"dst_ip\"] = clean_df[\"dst_ip\"].replace('::1', value=\"0\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HO2a6ef4Cxl3"
   },
   "outputs": [],
   "source": [
    "clean_x = clean_df.iloc[:, :13]\n",
    "column_trans = make_column_transformer((OneHotEncoder(sparse=False), ['Protocol', 'http_request_method', 'http_request_referrer', 'url_path', 'user_agent_original', 'sql_method', 'sql_query']),remainder='passthrough')\n",
    "test = column_trans.fit_transform(clean_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiRQu2ekMSlv"
   },
   "source": [
    "# K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kneed import KneeLocator\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation using MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "mms.fit(test)\n",
    "data_transformed = mms.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply PCA to our dataset with n_components=0.95. \n",
    "#This will select the number of components while preserving 95% of the variability in the data\n",
    "pca = PCA(n_components = 0.95)\n",
    "reduced = pca.fit_transform(data_transformed)\n",
    "label = kmeans.fit_predict(reduced)\n",
    "center = np.array(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot clustering graph with PCA\n",
    "plt.figure(figsize=(8,8))\n",
    "uniq = np.unique(label)\n",
    "for i in uniq:\n",
    "  plt.scatter(reduced[label == i , 0] , reduced[label == i , 1] , label = i)\n",
    "plt.scatter(center[:,0], center[:,1], marker=\"*\", c='black', s=250)\n",
    "plt.legend()\n",
    "plt.savefig('static/kmeans_scatterplot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiRQu2ekMSlv"
   },
   "source": [
    "# Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Table of Relationship between cluster and category\n",
    "data_orig['label_'] = kmeans.labels_\n",
    "ct = pd.crosstab(data_orig['category'], data_orig['label_'])\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiRQu2ekMSlv"
   },
   "source": [
    "# Elbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #the sum of squared distance between each point and the centroid in a cluster\n",
    "# wcss = []\n",
    "# for i in range(1,15):\n",
    "#    model = KMeans(n_clusters = i)\n",
    "#    model.fit(data_transformed)\n",
    "#    wcss.append(model.inertia_)\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.plot(range(1,15), wcss)\n",
    "# kn = KneeLocator(range(1,15), wcss, curve='convex', direction='decreasing')\n",
    "# plt.xlabel('Number of clusters')\n",
    "# plt.ylabel('WCSS')\n",
    "# plt.vlines(kn.knee, plt.ylim()[0], plt.ylim()[1], linestyles='dashed')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiRQu2ekMSlv"
   },
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZM3UFeBwmLhY"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(test, clean_y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W0mYlTn8MQDw",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = {}\n",
    "scores_list= []\n",
    "ktrainingtime={}\n",
    "kpredictiontime={}\n",
    "\n",
    "range_k = range(100, 160, 11)\n",
    "knn = \"\"\n",
    "skip = False\n",
    "\n",
    "for k in range_k:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    start_time = time.time()\n",
    "    knn.fit(x_train, y_train)\n",
    "    timetaken = time.time() - start_time\n",
    "    ktrainingtime[k] = timetaken\n",
    "    \n",
    "    timetaken = 0 \n",
    "    \n",
    "    start_time = time.time()\n",
    "    y_pred = knn.predict(x_test)\n",
    "    timetaken = time.time() - start_time\n",
    "    kpredictiontime[k] = timetaken\n",
    "    \n",
    "    scoring_metrics(y_test, y_pred, f\"{k}\")\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "print(ktrainingtime)\n",
    "print(kpredictiontime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiRQu2ekMSlv"
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#dictionary to store processing times\n",
    "algotrainingtime = {}\n",
    "algopredictiontime = {}\n",
    "\n",
    "clf = RandomForestClassifier(criterion=\"gini\",\n",
    "                             min_samples_split = 20,\n",
    "                             min_samples_leaf = 6,\n",
    "                             max_depth = 100,\n",
    "                             n_estimators=500,\n",
    "                             random_state=5) #can put any number here\n",
    "start_time =time.time()\n",
    "clf.fit(x_train, y_train)\n",
    "rftrainingtimetaken = time.time() - start_time\n",
    "algotrainingtime[\"Random Forest\"] = rftrainingtimetaken\n",
    "\n",
    "start_time =time.time()\n",
    "y_pred = clf.predict(x_test)\n",
    "rfpredictiontimetaken = time.time() - start_time\n",
    "algopredictiontime[\"Random Forest\"] = rfpredictiontimetaken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiRQu2ekMSlv"
   },
   "source": [
    "# Processing Time Comparision [RF & KNN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update the algotime dictionaries with KNN's results\n",
    "algotrainingtime[\"KNN\"] = ktrainingtime[133]\n",
    "algopredictiontime[\"KNN\"] = kpredictiontime[133]\n",
    "\n",
    "#Plot the processing time graphs\n",
    "plt.title('Processing Time')\n",
    "plt.xlabel('ML Algorithm')\n",
    "\n",
    "trainingtime = algotrainingtime.values()\n",
    "predictiontime = algopredictiontime.values()\n",
    "\n",
    "x_axis = np.arange(len(algotrainingtime))\n",
    "width = 0.2\n",
    "#multi bar charts\n",
    "plt.bar(x_axis, trainingtime, color = 'b', width = 0.3, edgecolor = 'black',label='Training Time')\n",
    "plt.bar(x_axis + width, predictiontime, color = 'g',width = 0.3, edgecolor ='black',label='Prediction Time')\n",
    "\n",
    "plt.xticks(x_axis,algotrainingtime.keys())\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig('static/ProcessingTime_Comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiRQu2ekMSlv"
   },
   "source": [
    "# Random Forest's Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score,recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "## ==== CONFUSION MATRIX ====\n",
    "# Get and reshape confusion matrix data\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Build the plot\n",
    "plt.figure(figsize=(16,7))\n",
    "sb.set(font_scale=1.4)\n",
    "sb.heatmap(matrix, annot=True, annot_kws={'size':10},\n",
    "            cmap=plt.cm.Greens, linewidths=0.2)\n",
    "\n",
    "# Add labels to the plot\n",
    "class_names = ['-','nmap_scan', 'port_scan', 'smtp_enumeration', 'sql_enumeration', 'web_enumeration']\n",
    "tick_marks = np.arange(len(class_names))\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "plt.xticks(tick_marks, class_names, rotation=25)\n",
    "plt.yticks(tick_marks2, class_names, rotation=0)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix for Random Forest Model')\n",
    "plt.show()\n",
    "\n",
    "RF_accuracy= accuracy_score(y_test, y_pred)\n",
    "algo_accuracy[\"Random Forest\"]= RF_accuracy\n",
    "\n",
    "RF_precision = precision_score(y_test, y_pred,average=\"weighted\")\n",
    "algo_precision[\"Random Forest\"] = RF_precision\n",
    "\n",
    "R1_f1_score = f1_score(y_test, y_pred,average=\"weighted\")\n",
    "algo_f1[\"Random Forest\"]=R1_f1_score\n",
    "\n",
    "R1_recall = recall_score(y_test, y_pred,average=\"weighted\")\n",
    "algo_recall[\"Random Forest\"]=R1_recall\n",
    "\n",
    "print(\"Classification Report \\n\" , classification_report(y_pred, y_test, labels=['-','nmap_scan', 'port_scan', 'smtp_enumeration', 'sql_enumeration', 'web_enumeration'], output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiRQu2ekMSlv"
   },
   "source": [
    "# KNN's Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jdnmWet-MQDw",
    "outputId": "9751dff5-db89-424c-f556-49a843b772db"
   },
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "categories = ['-','nmap_scan', 'port_scan', 'smtp_enumeration', 'sql_enumeration', 'web_enumeration']\n",
    "ax.set_xticklabels(categories, rotation=45)\n",
    "                   \n",
    "sb.heatmap(confusion_matrix, annot=True, fmt='0', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "plt.title('KNN Confusion Matrix')\n",
    "plt.savefig('static/KNN_ConfusionMatrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiRQu2ekMSlv"
   },
   "source": [
    "# KNN's optimal value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCbXBW0jMQDx"
   },
   "outputs": [],
   "source": [
    "# plt.title('Optimal K')\n",
    "# plt.xlabel('K value')\n",
    "\n",
    "# k_value = list(accuracy_dict.keys())\n",
    "\n",
    "# algo_accuracy[\"KNN\"]= accuracy_dict['133']\n",
    "# plt.plot(k_value, accuracy_dict.values(), label = \"Accuracy\", linestyle=\"-\")\n",
    "# plt.plot(k_value, precision_dict.values(), label = \"Precision\", linestyle=\"--\")\n",
    "# plt.plot(k_value, f1_dict.values(), label = \"F1 Score\", linestyle=\"-.\")\n",
    "\n",
    "# plt.legend(loc=\"upper right\")\n",
    "# plt.savefig('static/KNN_graph.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiRQu2ekMSlv"
   },
   "source": [
    "# Accuracy & Precision Comparison (RF & KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Accuracy and Precision Comparison')\n",
    "plt.xlabel('ML Algorithm')\n",
    "\n",
    "#Defining data to display\n",
    "algo_accuracy[\"KNN\"]= accuracy_dict['133']\n",
    "algo_precision['KNN']= precision_dict['133']\n",
    "\n",
    "accuracy = algo_accuracy.values()\n",
    "precision = algo_precision.values()\n",
    "x_axis = np.arange(len(algo_accuracy))\n",
    "width = 0.2\n",
    "\n",
    "#multi bar charts\n",
    "plt.bar(x_axis, accuracy, color = 'b', width = 0.3, edgecolor = 'black',label='KNN')\n",
    "plt.bar(x_axis + width, precision, color = 'g',width = 0.3, edgecolor ='black',label='Random Forest')\n",
    "\n",
    "plt.xticks(x_axis,['Accuracy', 'Precision'])\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('static/AnP_Comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiRQu2ekMSlv"
   },
   "source": [
    "# Accuracy Comparison alone -dk if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Accuracy')\n",
    "plt.xlabel('ML Algorithm')\n",
    "\n",
    "algo_accuracy[\"KNN\"]= accuracy_dict['133']\n",
    "accuracy = algo_accuracy.values()\n",
    "\n",
    "x_axis = algo_accuracy.keys()\n",
    "plt.bar(x_axis, accuracy,edgecolor = 'black', color=['b', 'g'])\n",
    "\n",
    "plt.savefig('static/Accuracy_comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiRQu2ekMSlv"
   },
   "source": [
    "# Precision Comparison alone -dk if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Precision Score')\n",
    "plt.xlabel('ML Algorithm')\n",
    "\n",
    "algo_precision[\"KNN\"]= precision_dict['133']\n",
    "precisionscores = algo_precision.values()\n",
    "\n",
    "x_axis = algo_precision.keys()\n",
    "\n",
    "plt.bar(x_axis, precisionscores,edgecolor = 'black', label = \"F1 Scores\", color=['b', 'g'])\n",
    "\n",
    "plt.savefig('static/precision_comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiRQu2ekMSlv"
   },
   "source": [
    "# F1_Score Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('F1 Score')\n",
    "plt.xlabel('ML Algorithm')\n",
    "\n",
    "algo_f1[\"KNN\"]= f1_dict['133']\n",
    "f1_scores = algo_f1.values()\n",
    "print(f1_scores)\n",
    "x_axis = algo_f1.keys()\n",
    "print(x_axis)\n",
    "plt.bar(x_axis, f1_scores,edgecolor = 'black', label = \"F1 Scores\", color=['b', 'g'])\n",
    "\n",
    "plt.savefig('static/F1_comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiRQu2ekMSlv"
   },
   "source": [
    "# Recall Score Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Recall Score')\n",
    "plt.xlabel('ML Algorithm')\n",
    "\n",
    "algo_recall[\"KNN\"]= recall_dict['133']\n",
    "recall = algo_recall.values()\n",
    "print(recall)\n",
    "x_axis = algo_recall.keys()\n",
    "print(x_axis)\n",
    "plt.bar(x_axis, recall,edgecolor = 'black', label = \"recall\", color=['b', 'g'])\n",
    "\n",
    "plt.savefig('static/Recall_comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tLGFsrgfMQD7"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from flask import Flask, render_template, Response, url_for\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('help.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
